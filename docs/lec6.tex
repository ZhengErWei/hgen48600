% -----------------------------*- LaTeX -*------------------------------
\documentclass[12pt]{report}
\usepackage{scribe_hgen486}
\begin{document}

\scribe{Marcos Vieira}		% required
\lecturenumber{6}			% required, must be a number
\lecturedate{January 21}		% required, omit year
\lecturer{John Novembre} 

\maketitle

% please leave this comment 
\framebox[.95\textwidth]{\parbox{.93\textwidth}{ {{\bf Note:}} These
lecture notes are still rough, and have only have been mildly
proofread.  }}
\vspace*{.1in}


% feel free to delete content below this line 
% ----------------------------------------------------------------------
\section*{Discrete-time Markov Chains}
	\bigskip
		\begin{center}
			$X_1 \rightarrow X_2 \rightarrow ... \rightarrow X_t$ 
		\end{center}
		
		\textbf{Markov property}:
	
		\bigskip$P(X_t = j  \  | \   X_{t-1} = i_{t-1}, \  X_{t-2} = i_{t-2}, \ ..., \  X_1 = i_1) = P(X_t = j \ | \  X_{t-1} = i_{t-1})$
	
		\bigskip The chain is time-homogeneous if, for all $t$:
		
		\bigskip $P(X_t = j \ | \ X_{t-1} = i) = P_{ij}$

		\bigskip Since the system must move to one of the states:
		
		\bigskip $\sum\limits_{j \in S}P_{ij} = 1$
		
		\bigskip We can collect the transition probabilities into a matrix $\mathbf{P}$. Because the rows of such a matrix specify probability distributions, the matrix is said to be a ``stochastic matrix". For example:
		
		\begin{center}
		\begin{align}
		\mathbf{P} =
		\begin{bmatrix}
			 P_{_{11}} & P_{_{12}} \\
			P_{_{21}}  & P_{_{22}}\\
		\end{bmatrix}
		=
		\begin{bmatrix}
			0.8 & 0.2 \\
			0.3 & 0.7 \\
		\end{bmatrix} \nonumber
		\end{align}
		\end{center}

		
		\bigskip An example from phylogenetics gives transition probabilities among nucleotides A, T, C and G, represented in the rows and columns:
		
		\begin{center}
		\begin{align}
		\mathbf{P} =
		\begin{bmatrix}
			0.999 & \frac{0.001}{3} & \frac{0.001}{3} & \frac{0.001}{3} \\
			\frac{0.001}{3} & 0.999 & \frac{0.001}{3} & \frac{0.001}{3} \\
			\frac{0.001}{3} & \frac{0.001}{3} & 0.999 & \frac{0.001}{3} \\
			\frac{0.001}{3} & \frac{0.001}{3} & \frac{0.001}{3} & 0.999\\
		\end{bmatrix} \nonumber
		\end{align}
		\end{center}
		
		\bigskip An example from population genetics is the Wright-Fisher model for how the the number $X_t$ of copies of an allele changes in a population over time:
		
		\bigskip $X_t \ | \  X_{t-1} = i \sim Binomial (N, \frac{i}{N})$
		
		\bigskip
		\bigskip What happens in $n$ steps?
		
    		\bigskip ${P_{ij}^{(n)}}$: $n$th step transition probabilities.
		
		\bigskip ${P_{ij}^{(n)}} = P(X_{n+k} = j \ | \ X_k = i)$, for $n \ge 0$, $i, j \ge 0$
		
		\bigskip
		\bigskip\textbf{Chapman-Kolmogorov equations}:
		
		\bigskip ${P_{ij}^{(n+m)}} = \sum\limits_{k} {P_{ik}}^{(n)}{P_{kj}}^{(m)} $ for all $n, m \ge 0$

		\bigskip Or, equivalently, in matrix algebra:
		
		\bigskip$\mathbf{P}^{(n+m)} = \mathbf{P}^{(n)}\mathbf{P}^{(m)}$
		
		\bigskip In general, for discrete-time Markov chains:
		
		\bigskip $\mathbf{P}^{(n)} = \mathbf{P}^{n}$
		
		\bigskip
		\bigskip\textbf{Reducible vs. irreducible chains}:
		
		\bigskip State $j$ is \emph{accessible} to state $i$ if it's possible for the chain to move from $i$ to $j$. If $i$ is accessible to $j$, $j$ is accessible to $i$, or both, states $i$ and $j$ \emph{communicate}.
		
		\bigskip\emph{Class of states}: a set of states that communicate.
		
		\bigskip\emph{Irreducible Markov chain}: a Markov chain with a single class (all states communicate).
		
		\bigskip
		\bigskip\textbf{Recurrent or transient states}:
		
		\bigskip$f_i$ : probability of returning to $i$ if starting at $i$, as $t \rightarrow \infty$
		
		\bigskip State $i$ is:
		
		\bigskip\emph{Recurrent}, if $f_i = 1$.
		
		\emph{Transient}, if $f_i < 1$.
		
		\bigskip
		\bigskip\textbf{Periodic vs. non-periodic states}
		
		\bigskip A state is periodic if the chain can't stay in it and has to leave before moving to the same state again:
		
		\bigskip$P(X_{t+1} = i \ | \ X_{t} = i) = 0$
		
		\bigskip Otherwise, the state is non-periodic.
		
		\bigskip
		\bigskip\emph{Ergodic Markov chains}:
		
		\bigskip A discrete-time Markov chain is \emph{ergodic} if it is irreducible and all of its states are recurrent and non-periodic.
		
		\bigskip If a discrete-time Markov chain is ergodic, then it's guaranteed to have a \emph{stationary distribution} (also known as an equilibrium distribution). That is, from any initial probability distribution of the states $\boldsymbol{\pi}^{(0)}$, there is a unique $\boldsymbol{\pi}$ such that:
		
		\bigskip $$ \lim_{t \to\infty}(\boldsymbol{\pi}^{(0)})^T \mathbf{P}^t = \boldsymbol{\pi}^T$$ 		
		
		\bigskip And $\boldsymbol{\pi}$ satisfies:
		
		\bigskip$\boldsymbol{\pi}^T\mathbf{P} = \boldsymbol{\pi}$
		
		\bigskip Which we can solve for $\boldsymbol{\pi}$. 
		
		\bigskip
		\bigskip\textbf{Eigenvalue decomposition of $\mathbf{P}$}:
		
		\bigskip If $\mathbf{V}$ and $\mathbf{\Lambda}$ are the eigenvector and eigenvalue matrices of $\mathbf{P}$, respectively, then:
		
		\bigskip $\mathbf{P} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1}$
		
		\bigskip $\mathbf{P}^k = \mathbf{V} \mathbf{\Lambda}^k \mathbf{V}^{-1}$
		
		\bigskip Usually, $\lambda_1 = 1$, $\lambda_2, \lambda_3, ... < 1$.
		
		\bigskip
		\bigskip\textbf{Time reversibility}:
		
		\bigskip$$Q_{ij} = P(X_{t-1} = i \ | \ X_t = j) = \frac{P(X_t = i \  | X_{t-1} = j) P(X_{t-1} = j)}{P(X_t = i)}$$ 		
		
		\bigskip If we are at the stationary distribution $\boldsymbol{\pi}$, this becomes:
		
		\bigskip$$Q_{ij} = \frac{P_{ij}\pi_j}{\pi_i}$$
		
		\bigskip In the special case where
		
		\bigskip$$P_{ij} = \frac{P_{ji}\pi_j}{\pi_i}$$

		\bigskip The chain is said to be \emph{time-reversible}:
		
		\bigskip$\pi_i P_{ij} = \pi_j P_{ji}$


\end{document}

